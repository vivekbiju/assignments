
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
     

# Load the dataset
df=pd.read_excel('/content/iris new assign.xls')
     

df
     
SL	SW	PL	PW	Classification
0	5.1	3.5	1.4	0.2	Iris-setosa
1	4.9	3.0	1.4	0.2	Iris-setosa
2	NaN	3.2	1.3	0.2	Iris-setosa
3	4.6	3.1	1.5	0.2	Iris-setosa
4	5.0	3.6	1.4	0.2	Iris-setosa
...	...	...	...	...	...
145	6.7	3.0	5.2	2.3	Iris-virginica
146	6.3	2.5	5.0	1.9	Iris-virginica
147	6.5	3.0	NaN	2.0	Iris-virginica
148	6.2	3.4	5.4	2.3	Iris-virginica
149	5.9	3.0	5.1	1.8	Iris-virginica
150 rows Ã— 5 columns


#Getting info
df.info()
     
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150 entries, 0 to 149
Data columns (total 5 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   SL              143 non-null    float64
 1   SW              144 non-null    float64
 2   PL              144 non-null    float64
 3   PW              150 non-null    float64
 4   Classification  150 non-null    object 
dtypes: float64(4), object(1)
memory usage: 6.0+ KB

# Checking missing values
df.isnull().sum()
     
SL                7
SW                6
PL                6
PW                0
Classification    0
dtype: int64

df['SL'] = df['SL'].fillna(df['SL'].median())
df['SW'] = df['SW'].fillna(df['SW'].median())
df['PL'] = df['PL'].fillna(df['PL'].median())
     

df.isnull().sum()
     
SL                0
SW                0
PL                0
PW                0
Classification    0
dtype: int64

# Encoding categorical target variable
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Classification']= le.fit_transform(df['Classification'])

     

df.head()
     
SL	SW	PL	PW	Classification
0	5.1	3.5	1.4	0.2	0
1	4.9	3.0	1.4	0.2	0
2	5.8	3.2	1.3	0.2	0
3	4.6	3.1	1.5	0.2	0
4	5.0	3.6	1.4	0.2	0

#Splitting the dataset into features (X) and target (y)
X = df.drop('Classification', axis=1)
y = df['Classification']
     

# Splitting the dataset into training set and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
     

#3. Classification Models Evaluation
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
     

# Initialize models
models = {
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Support Vector Machine": SVC(),
    "Logistic Regression": LogisticRegression()}
     

# Initialize models
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy

# Finding the best model
best_model = max(results, key=results.get)
best_accuracy = results[best_model]

print("Results:\n", results)
print("Best Model:", best_model)
print("Best Accuracy:", best_accuracy)
